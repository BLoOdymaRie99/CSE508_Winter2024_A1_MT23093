{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7541570,"sourceType":"datasetVersion","datasetId":4391639}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os  # Importing the os module for operating system related functionalities\nimport nltk  # Importing the Natural Language Toolkit for NLP operations\nimport string  # Importing the string module for string manipulation\nimport pickle  # Importing pickle module for serializing and deserializing Python objects\n\nfrom nltk.tokenize import word_tokenize  # Importing word_tokenize function for tokenization\nfrom nltk.corpus import stopwords  # Importing stopwords from NLTK corpus for removing common words\n\n# Download NLTK resources\n# nltk.download('punkt')  # Download the Punkt tokenizer models\n# nltk.download('stopwords')  # Download the stopwords corpus\n\n# Define function for preprocessing\ndef preprocess_text(text):\n    # Lowercase the text\n    text = text.lower()\n    \n    # Tokenization using NLTK's word_tokenize\n    tokens = word_tokenize(text)\n    \n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))  # Retrieve English stopwords\n    tokens = [word for word in tokens if word not in stop_words]  # Filter out stopwords\n    \n    # Remove punctuations\n    tokens = [word for word in tokens if word not in string.punctuation]  # Filter out punctuation symbols\n    \n    # Remove blank space tokens\n    tokens = [word for word in tokens if word.strip()]  # Filter out empty tokens\n    \n    return tokens  # Return the preprocessed tokens\n\n# Function to create positional index and various steps\ndef create_positional_index(folder_path):\n    positional_index = {}  # Initialize an empty positional index dictionary\n    for file_name in os.listdir(folder_path):  # Iterate through each file in the folder\n        file_path = os.path.join(folder_path, file_name)  # Construct the full file path\n        with open(file_path, 'r') as file:  # Open the file in read mode\n            text = file.read()  # Read the contents of the file\n        tokens = preprocess_text(text)  # Preprocess the text of the file\n        for position, token in enumerate(tokens):  # Iterate through each token in the file\n            if token not in positional_index:  # If token is not in positional index\n                positional_index[token] = {}  # Initialize an empty dictionary for the token\n            if file_name not in positional_index[token]:  # If file not in positional index for token\n                positional_index[token][file_name] = []  # Initialize an empty list for the file\n            positional_index[token][file_name].append(position)  # Append the position to the list\n    return positional_index  # Return the positional index dictionary\n\n# Function to save positional index using pickle\ndef save_positional_index(positional_index, file_path):\n    with open(file_path, 'wb') as file:  # Open the file in write-binary mode\n        pickle.dump(positional_index, file)  # Serialize and write the positional index to the file\n\n# Function to load positional index using pickle\ndef load_positional_index(file_path):\n    with open(file_path, 'rb') as file:  # Open the file in read-binary mode\n        positional_index = pickle.load(file)  # Deserialize and load the positional index from the file\n    return positional_index  # Return the loaded positional index\n\n# Function to process queries using positional index\ndef process_queries(positional_index, queries):\n    results = []  # Initialize an empty list to store query results\n    for query in queries:  # Iterate through each query\n        query_terms = preprocess_text(query)  # Preprocess the query text\n        retrieved_docs = None  # Initialize variable to store retrieved documents\n        for term in query_terms:  # Iterate through each term in the query\n            if term in positional_index:  # Check if term exists in the positional index\n                if retrieved_docs is None:  # If retrieved_docs is None\n                    retrieved_docs = set(positional_index[term].keys())  # Initialize with document keys\n                else:  # If retrieved_docs is not None\n                    retrieved_docs &= set(positional_index[term].keys())  # Intersect with document keys\n        results.append(retrieved_docs)  # Append retrieved documents to results list\n    return results  # Return the list of query results\n\n# Function to get user input\ndef get_user_input():\n    num_queries = int(input(\"Enter the number of queries to execute: \"))  # Prompt user for number of queries\n    queries = []  # Initialize an empty list to store queries\n    for _ in range(num_queries):  # Iterate for each query\n        query = input(\"Enter phrase query: \")  # Prompt user to enter query\n        queries.append(query)  # Append the query to the list of queries\n    return queries  # Return the list of queries\n\n# Function to display results\ndef display_results(results):\n    for i, docs in enumerate(results, 1):  # Iterate through each query result\n        print(f\"Number of documents retrieved for query {i} using positional index: {len(docs)}\")\n        print(f\"Names of documents retrieved for query {i} using positional index: {', '.join(docs)}\")\n\n# Main function\ndef main():\n    # Path to the folder containing your text files\n    folder_path = '/kaggle/input/ir-text/text_files'  # Set the path to the folder containing text files\n    \n    # Create positional index\n    positional_index = create_positional_index(folder_path)  # Create the positional index\n    \n    # Save positional index\n    save_positional_index(positional_index, '/kaggle/working/positional_index.pickle')  # Save the positional index\n    \n    # Load positional index\n    loaded_positional_index = load_positional_index('/kaggle/working/positional_index.pickle')  # Load the positional index\n    \n    # Get user input\n    queries = get_user_input()  # Get queries from user\n    \n    # Process queries\n    results = process_queries(loaded_positional_index, queries)  # Process queries using positional index\n    \n    # Display results\n    display_results(results)  # Display the query results\n\nif __name__ == \"__main__\":\n    main()  # Execute the main function\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T17:05:38.592933Z","iopub.execute_input":"2024-02-09T17:05:38.593384Z","iopub.status.idle":"2024-02-09T17:05:51.385065Z","shell.execute_reply.started":"2024-02-09T17:05:38.593352Z","shell.execute_reply":"2024-02-09T17:05:51.383530Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the number of queries to execute:  1\nEnter phrase query:  car\n"},{"name":"stdout","text":"Number of documents retrieved for query 1 using positional index: 6\nNames of documents retrieved for query 1 using positional index: file174.txt, file542.txt, file886.txt, file166.txt, file264.txt, file746.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-09T17:04:17.265555Z","iopub.execute_input":"2024-02-09T17:04:17.266851Z","iopub.status.idle":"2024-02-09T17:04:31.602629Z","shell.execute_reply.started":"2024-02-09T17:04:17.266782Z","shell.execute_reply":"2024-02-09T17:04:31.601166Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the number of queries to execute:  1\nEnter phrase query:  car bag in a canister\n"},{"name":"stdout","text":"Number of documents retrieved for query 1 using positional index: 2\nNames of documents retrieved for query 1 using positional index: file174.txt, file886.txt\n","output_type":"stream"}]}]}