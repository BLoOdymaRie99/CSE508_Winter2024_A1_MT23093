{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7541570,"sourceType":"datasetVersion","datasetId":4391639}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\nimport os\n\n# Define the path to the directory containing your text files\ninput_directory = '/kaggle/input/ir-text/text_files'\noutput_directory = '/kaggle/working/lowercase_files'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# List all files in the directory\nfiles = os.listdir(input_directory)\n\n# Select 5 sample files\nsample_files = files[:5]\n\n# Iterate over the sample files\nfor file_name in sample_files:\n    # Construct the full path to the input file\n    input_file_path = os.path.join(input_directory, file_name)\n\n    # Read the content of the original file\n    with open(input_file_path, 'r', encoding='utf-8') as file:\n        original_content = file.read()\n\n    # Preprocess the text: lowercase the text\n    preprocessed_content = original_content.lower()\n\n    # Construct the full path to the output file\n    output_file_path = os.path.join(output_directory, file_name)\n\n    # Save the preprocessed content to a new file\n    with open(output_file_path, 'w', encoding='utf-8') as file:\n        file.write(preprocessed_content)\n\n    # Print a message indicating the file has been saved\n    print(f\"Preprocessed content of {file_name} is {preprocessed_content}\")\n\n    # Print the original content before preprocessing\n    print(f\"\\nOriginal content of {file_name}:\")\n    print(original_content)\n\n    # Print a separator for clarity\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T12:03:53.426409Z","iopub.execute_input":"2024-02-09T12:03:53.426935Z","iopub.status.idle":"2024-02-09T12:03:53.455479Z","shell.execute_reply.started":"2024-02-09T12:03:53.426894Z","shell.execute_reply":"2024-02-09T12:03:53.454395Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Preprocessed content of file314.txt is the amazon advertised pictures of this item is a fender fte3 pre amp. the description says it's a fishman isys iii type. i googled it and found out there's two version of pre amp type of this t bucket 300 ce series. the one i got today is a fishman type pre amp which is for me much better that fte3. out of the box, i fell inlove with the color and design. mine is a 3 tone sunburst. the action is just right for me. the tone/sound is awesome. i hooked it up in my vox amp and i have to say this thing really rocks. of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. i'm a family man with two kids and i am not gonna spend a thousand bucks just for a hobby. amplified or not i love the tone of this baby. for it's appearance, sound quality, and of course the price, i'm giving it a five stars.\n\ni uploaded some pictures (above) of the fishman pre amp version of this t bucket series. :o)..\n\nOriginal content of file314.txt:\nThe Amazon advertised pictures of this item is a Fender FTE3 pre amp. The description says it's a Fishman Isys III type. I googled it and found out there's two version of pre amp type of this T Bucket 300 CE series. The one I got today is a Fishman type pre amp which is for me much better that FTE3. Out of the box, I fell inlove with the color and design. Mine is a 3 tone sunburst. The action is just right for me. The tone/sound is awesome. I hooked it up in my Vox amp and I have to say this thing really rocks. Of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. I'm a family man with two kids and I am not gonna spend a thousand bucks just for a hobby. Amplified or not I love the tone of this baby. For it's appearance, sound quality, and of course THE PRICE, I'm giving it a five stars.\n\nI uploaded some pictures (above) of the Fishman pre amp version of this T bucket series. :O)..\n\n==================================================\n\nPreprocessed content of file998.txt is i really like the simplicity of this bridge. it adjusts easy for string height and length. it comes with all the mounting screws and even a small allen wrench to make the height adjustments. the provided mounting screws are phillips head screws. the one thing that i missed when i ordered this was the fact that it is not a bridge for string-thru the guitar body placement. the strings dead end to the stop-flair of the plate. i included a picture of this so it may help to make others aware that it is not for string-thru applications. no biggie tho for me, i will use it on another project now.\n\nOriginal content of file998.txt:\nI really like the simplicity of this bridge. It adjusts easy for string height and length. It comes with all the mounting screws and even a small allen wrench to make the height adjustments. The provided mounting screws are Phillips head screws. The one thing that I missed when I ordered this was the fact that it is not a bridge for string-thru the guitar body placement. The strings dead end to the stop-flair of the plate. I included a picture of this so it may help to make others aware that it is not for string-thru applications. No biggie tho for me, I will use it on another project now.\n\n==================================================\n\nPreprocessed content of file603.txt is truthfully, i had no idea that the even were ukulele capos. but why not? i use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nregardless, this is a well made, lightweight capo. weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. this capo won't make your soprano uke neck heavy. the soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. a useful tool for ukuleleists.\n\nOriginal content of file603.txt:\nTruthfully, I had no idea that the even were ukulele capos. But why not? I use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nRegardless, this is a well made, lightweight capo. Weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. This capo won't make your soprano uke neck heavy. The soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. A useful tool for ukuleleists.\n\n==================================================\n\nPreprocessed content of file175.txt is my es*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\nOriginal content of file175.txt:\nMy ES*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\n==================================================\n\nPreprocessed content of file457.txt is i bought a used mim strat that came with a black pick guard and creamish colored pickups. the guitar was great but the pick guard wasn't my style. i put this on and now i love the look of this guitar. highly recommend.\n\nOriginal content of file457.txt:\nI bought a used MIM strat that came with a black pick guard and creamish colored pickups. The guitar was great but the pick guard wasn't my style. I put this on and now I love the look of this guitar. Highly recommend.\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\nimport os\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\n\n# Download NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Define the path to the directory containing your text files\ninput_directory = '/kaggle/input/ir-text/text_files'\noutput_directory = '/kaggle/working/Tokenized_files'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Set of English stopwords\nstop_words = set(stopwords.words('english'))\n\n# List all files in the directory\nfiles = os.listdir(input_directory)\n\n# Select 5 sample files\nsample_files = files[:5]\n\n# Iterate over the sample files\nfor file_name in sample_files:\n    # Construct the full path to the input file\n    input_file_path = os.path.join(input_directory, file_name)\n\n    # Read the content of the original file\n    with open(input_file_path, 'r', encoding='utf-8') as file:\n        original_content = file.read()\n\n    # Preprocess the text: lowercase the text\n    preprocessed_content = original_content.lower()\n\n    # Tokenization\n    tokens = word_tokenize(preprocessed_content)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stop_words]\n\n    # Remove punctuations\n    tokens = [token for token in tokens if token not in string.punctuation]\n\n    # Remove blank space tokens\n    tokens = [token for token in tokens if token.strip() != '']\n\n    # Construct the full path to the output file\n    output_file_path = os.path.join(output_directory, file_name)\n\n    # Save the preprocessed content to a new file\n    with open(output_file_path, 'w', encoding='utf-8') as file:\n        file.write(' '.join(tokens))\n\n    # Print original content before preprocessing\n    print(f\"Original content of {file_name}:\")\n    print(original_content)\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Print preprocessed content after all preprocessing steps\n    print(f\"Preprocessed content of {file_name}:\")\n    print(' '.join(tokens))\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n    \n    ###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:03:53.458070Z","iopub.execute_input":"2024-02-09T12:03:53.458969Z","iopub.status.idle":"2024-02-09T12:03:53.491757Z","shell.execute_reply.started":"2024-02-09T12:03:53.458923Z","shell.execute_reply":"2024-02-09T12:03:53.490548Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nOriginal content of file314.txt:\nThe Amazon advertised pictures of this item is a Fender FTE3 pre amp. The description says it's a Fishman Isys III type. I googled it and found out there's two version of pre amp type of this T Bucket 300 CE series. The one I got today is a Fishman type pre amp which is for me much better that FTE3. Out of the box, I fell inlove with the color and design. Mine is a 3 tone sunburst. The action is just right for me. The tone/sound is awesome. I hooked it up in my Vox amp and I have to say this thing really rocks. Of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. I'm a family man with two kids and I am not gonna spend a thousand bucks just for a hobby. Amplified or not I love the tone of this baby. For it's appearance, sound quality, and of course THE PRICE, I'm giving it a five stars.\n\nI uploaded some pictures (above) of the Fishman pre amp version of this T bucket series. :O)..\n\n==================================================\n\nPreprocessed content of file314.txt:\namazon advertised pictures item fender fte3 pre amp description says 's fishman isys iii type googled found 's two version pre amp type bucket 300 ce series one got today fishman type pre amp much better fte3 box fell inlove color design mine 3 tone sunburst action right tone/sound awesome hooked vox amp say thing really rocks course get better sounding acoustic/electric guitar much expensive price 'm family man two kids gon na spend thousand bucks hobby amplified love tone baby 's appearance sound quality course price 'm giving five stars uploaded pictures fishman pre amp version bucket series ..\n\n==================================================\n\nOriginal content of file998.txt:\nI really like the simplicity of this bridge. It adjusts easy for string height and length. It comes with all the mounting screws and even a small allen wrench to make the height adjustments. The provided mounting screws are Phillips head screws. The one thing that I missed when I ordered this was the fact that it is not a bridge for string-thru the guitar body placement. The strings dead end to the stop-flair of the plate. I included a picture of this so it may help to make others aware that it is not for string-thru applications. No biggie tho for me, I will use it on another project now.\n\n==================================================\n\nPreprocessed content of file998.txt:\nreally like simplicity bridge adjusts easy string height length comes mounting screws even small allen wrench make height adjustments provided mounting screws phillips head screws one thing missed ordered fact bridge string-thru guitar body placement strings dead end stop-flair plate included picture may help make others aware string-thru applications biggie tho use another project\n\n==================================================\n\nOriginal content of file603.txt:\nTruthfully, I had no idea that the even were ukulele capos. But why not? I use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nRegardless, this is a well made, lightweight capo. Weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. This capo won't make your soprano uke neck heavy. The soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. A useful tool for ukuleleists.\n\n==================================================\n\nPreprocessed content of file603.txt:\ntruthfully idea even ukulele capos use guitars banjo certainly times might want shift key without transposing take advantage open strings regardless well made lightweight capo weight particular importance dealing instrument 's already small lightweight hernally played without strap capo wo n't make soprano uke neck heavy soft rubber surface moveable jaw good job pressing synthetic strings fret without stretching tune useful tool ukuleleists\n\n==================================================\n\nOriginal content of file175.txt:\nMy ES*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\n==================================================\n\nPreprocessed content of file175.txt:\nes*335 fit loose needed padding added keep guitar snug n't mind 's good deal ...\n\n==================================================\n\nOriginal content of file457.txt:\nI bought a used MIM strat that came with a black pick guard and creamish colored pickups. The guitar was great but the pick guard wasn't my style. I put this on and now I love the look of this guitar. Highly recommend.\n\n==================================================\n\nPreprocessed content of file457.txt:\nbought used mim strat came black pick guard creamish colored pickups guitar great pick guard n't style put love look guitar highly recommend\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\n\noutput_directory = '/kaggle/working/stopwords_files'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Set of English stopwords\nstop_words = set(stopwords.words('english'))\n\n# List all files in the directory\nfiles = os.listdir(input_directory)\n\n# Select 5 sample files\nsample_files = files[:5]\n\n# Iterate over the sample files\nfor file_name in sample_files:\n    # Construct the full path to the input file\n    input_file_path = os.path.join(input_directory, file_name)\n\n    # Read the content of the original file\n    with open(input_file_path, 'r', encoding='utf-8') as file:\n        original_content = file.read()\n\n    # Preprocess the text: lowercase the text\n    preprocessed_content = original_content.lower()\n\n    # Tokenization\n    tokens = word_tokenize(preprocessed_content)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stop_words]\n\n    # Remove punctuations\n    tokens = [token for token in tokens if token not in string.punctuation]\n\n    # Remove blank space tokens\n    tokens = [token for token in tokens if token.strip() != '']\n\n    # Construct the full path to the output file\n    output_file_path = os.path.join(output_directory, file_name)\n\n    # Save the preprocessed content to a new file\n    with open(output_file_path, 'w', encoding='utf-8') as file:\n        file.write(' '.join(tokens))\n\n    # Print original content before removing stopwords\n    print(f\"Original content of {file_name}:\")\n    print(original_content)\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Print preprocessed content after removing stopwords\n    print(f\"Preprocessed content of {file_name} after removing stopwords:\")\n    print(' '.join(tokens))\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:03:53.493535Z","iopub.execute_input":"2024-02-09T12:03:53.493878Z","iopub.status.idle":"2024-02-09T12:03:53.520957Z","shell.execute_reply.started":"2024-02-09T12:03:53.493836Z","shell.execute_reply":"2024-02-09T12:03:53.519951Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Original content of file314.txt:\nThe Amazon advertised pictures of this item is a Fender FTE3 pre amp. The description says it's a Fishman Isys III type. I googled it and found out there's two version of pre amp type of this T Bucket 300 CE series. The one I got today is a Fishman type pre amp which is for me much better that FTE3. Out of the box, I fell inlove with the color and design. Mine is a 3 tone sunburst. The action is just right for me. The tone/sound is awesome. I hooked it up in my Vox amp and I have to say this thing really rocks. Of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. I'm a family man with two kids and I am not gonna spend a thousand bucks just for a hobby. Amplified or not I love the tone of this baby. For it's appearance, sound quality, and of course THE PRICE, I'm giving it a five stars.\n\nI uploaded some pictures (above) of the Fishman pre amp version of this T bucket series. :O)..\n\n==================================================\n\nPreprocessed content of file314.txt after removing stopwords:\namazon advertised pictures item fender fte3 pre amp description says 's fishman isys iii type googled found 's two version pre amp type bucket 300 ce series one got today fishman type pre amp much better fte3 box fell inlove color design mine 3 tone sunburst action right tone/sound awesome hooked vox amp say thing really rocks course get better sounding acoustic/electric guitar much expensive price 'm family man two kids gon na spend thousand bucks hobby amplified love tone baby 's appearance sound quality course price 'm giving five stars uploaded pictures fishman pre amp version bucket series ..\n\n==================================================\n\nOriginal content of file998.txt:\nI really like the simplicity of this bridge. It adjusts easy for string height and length. It comes with all the mounting screws and even a small allen wrench to make the height adjustments. The provided mounting screws are Phillips head screws. The one thing that I missed when I ordered this was the fact that it is not a bridge for string-thru the guitar body placement. The strings dead end to the stop-flair of the plate. I included a picture of this so it may help to make others aware that it is not for string-thru applications. No biggie tho for me, I will use it on another project now.\n\n==================================================\n\nPreprocessed content of file998.txt after removing stopwords:\nreally like simplicity bridge adjusts easy string height length comes mounting screws even small allen wrench make height adjustments provided mounting screws phillips head screws one thing missed ordered fact bridge string-thru guitar body placement strings dead end stop-flair plate included picture may help make others aware string-thru applications biggie tho use another project\n\n==================================================\n\nOriginal content of file603.txt:\nTruthfully, I had no idea that the even were ukulele capos. But why not? I use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nRegardless, this is a well made, lightweight capo. Weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. This capo won't make your soprano uke neck heavy. The soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. A useful tool for ukuleleists.\n\n==================================================\n\nPreprocessed content of file603.txt after removing stopwords:\ntruthfully idea even ukulele capos use guitars banjo certainly times might want shift key without transposing take advantage open strings regardless well made lightweight capo weight particular importance dealing instrument 's already small lightweight hernally played without strap capo wo n't make soprano uke neck heavy soft rubber surface moveable jaw good job pressing synthetic strings fret without stretching tune useful tool ukuleleists\n\n==================================================\n\nOriginal content of file175.txt:\nMy ES*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\n==================================================\n\nPreprocessed content of file175.txt after removing stopwords:\nes*335 fit loose needed padding added keep guitar snug n't mind 's good deal ...\n\n==================================================\n\nOriginal content of file457.txt:\nI bought a used MIM strat that came with a black pick guard and creamish colored pickups. The guitar was great but the pick guard wasn't my style. I put this on and now I love the look of this guitar. Highly recommend.\n\n==================================================\n\nPreprocessed content of file457.txt after removing stopwords:\nbought used mim strat came black pick guard creamish colored pickups guitar great pick guard n't style put love look guitar highly recommend\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\n\noutput_directory = '/kaggle/working/punctuations_files'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Set of English stopwords\nstop_words = set(stopwords.words('english'))\n\n# List all files in the directory\nfiles = os.listdir(input_directory)\n\n# Select 5 sample files\nsample_files = files[:5]\n\n# Iterate over the sample files\nfor file_name in sample_files:\n    # Construct the full path to the input file\n    input_file_path = os.path.join(input_directory, file_name)\n\n    # Read the content of the original file\n    with open(input_file_path, 'r', encoding='utf-8') as file:\n        original_content = file.read()\n\n    # Preprocess the text: lowercase the text\n    preprocessed_content = original_content.lower()\n\n    # Tokenization\n    tokens = word_tokenize(preprocessed_content)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stop_words]\n\n    # Remove punctuation\n    tokens = [token for token in tokens if token not in string.punctuation]\n\n    # Construct the full path to the output file\n    output_file_path = os.path.join(output_directory, file_name)\n\n    # Save the preprocessed content to a new file\n    with open(output_file_path, 'w', encoding='utf-8') as file:\n        file.write(' '.join(tokens))\n\n    # Print original content before removing punctuation\n    print(f\"Original content of {file_name}:\")\n    print(original_content)\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Print preprocessed content after removing punctuation\n    print(f\"Preprocessed content of {file_name} after removing punctuation:\")\n    print(' '.join(tokens))\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n    ###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:03:53.523456Z","iopub.execute_input":"2024-02-09T12:03:53.524361Z","iopub.status.idle":"2024-02-09T12:03:53.553038Z","shell.execute_reply.started":"2024-02-09T12:03:53.524316Z","shell.execute_reply":"2024-02-09T12:03:53.551587Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Original content of file314.txt:\nThe Amazon advertised pictures of this item is a Fender FTE3 pre amp. The description says it's a Fishman Isys III type. I googled it and found out there's two version of pre amp type of this T Bucket 300 CE series. The one I got today is a Fishman type pre amp which is for me much better that FTE3. Out of the box, I fell inlove with the color and design. Mine is a 3 tone sunburst. The action is just right for me. The tone/sound is awesome. I hooked it up in my Vox amp and I have to say this thing really rocks. Of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. I'm a family man with two kids and I am not gonna spend a thousand bucks just for a hobby. Amplified or not I love the tone of this baby. For it's appearance, sound quality, and of course THE PRICE, I'm giving it a five stars.\n\nI uploaded some pictures (above) of the Fishman pre amp version of this T bucket series. :O)..\n\n==================================================\n\nPreprocessed content of file314.txt after removing punctuation:\namazon advertised pictures item fender fte3 pre amp description says 's fishman isys iii type googled found 's two version pre amp type bucket 300 ce series one got today fishman type pre amp much better fte3 box fell inlove color design mine 3 tone sunburst action right tone/sound awesome hooked vox amp say thing really rocks course get better sounding acoustic/electric guitar much expensive price 'm family man two kids gon na spend thousand bucks hobby amplified love tone baby 's appearance sound quality course price 'm giving five stars uploaded pictures fishman pre amp version bucket series ..\n\n==================================================\n\nOriginal content of file998.txt:\nI really like the simplicity of this bridge. It adjusts easy for string height and length. It comes with all the mounting screws and even a small allen wrench to make the height adjustments. The provided mounting screws are Phillips head screws. The one thing that I missed when I ordered this was the fact that it is not a bridge for string-thru the guitar body placement. The strings dead end to the stop-flair of the plate. I included a picture of this so it may help to make others aware that it is not for string-thru applications. No biggie tho for me, I will use it on another project now.\n\n==================================================\n\nPreprocessed content of file998.txt after removing punctuation:\nreally like simplicity bridge adjusts easy string height length comes mounting screws even small allen wrench make height adjustments provided mounting screws phillips head screws one thing missed ordered fact bridge string-thru guitar body placement strings dead end stop-flair plate included picture may help make others aware string-thru applications biggie tho use another project\n\n==================================================\n\nOriginal content of file603.txt:\nTruthfully, I had no idea that the even were ukulele capos. But why not? I use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nRegardless, this is a well made, lightweight capo. Weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. This capo won't make your soprano uke neck heavy. The soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. A useful tool for ukuleleists.\n\n==================================================\n\nPreprocessed content of file603.txt after removing punctuation:\ntruthfully idea even ukulele capos use guitars banjo certainly times might want shift key without transposing take advantage open strings regardless well made lightweight capo weight particular importance dealing instrument 's already small lightweight hernally played without strap capo wo n't make soprano uke neck heavy soft rubber surface moveable jaw good job pressing synthetic strings fret without stretching tune useful tool ukuleleists\n\n==================================================\n\nOriginal content of file175.txt:\nMy ES*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\n==================================================\n\nPreprocessed content of file175.txt after removing punctuation:\nes*335 fit loose needed padding added keep guitar snug n't mind 's good deal ...\n\n==================================================\n\nOriginal content of file457.txt:\nI bought a used MIM strat that came with a black pick guard and creamish colored pickups. The guitar was great but the pick guard wasn't my style. I put this on and now I love the look of this guitar. Highly recommend.\n\n==================================================\n\nPreprocessed content of file457.txt after removing punctuation:\nbought used mim strat came black pick guard creamish colored pickups guitar great pick guard n't style put love look guitar highly recommend\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.\n\n\noutput_directory = '/kaggle/working/blank_space_files'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Set of English stopwords\nstop_words = set(stopwords.words('english'))\n\n# List all files in the directory\nfiles = os.listdir(input_directory)\n\n# Select 5 sample files\nsample_files = files[:5]\n\n# Iterate over the sample files\nfor file_name in sample_files:\n    # Construct the full path to the input file\n    input_file_path = os.path.join(input_directory, file_name)\n\n    # Read the content of the original file\n    with open(input_file_path, 'r', encoding='utf-8') as file:\n        original_content = file.read()\n\n    # Preprocess the text: lowercase the text\n    preprocessed_content = original_content.lower()\n\n    # Tokenization\n    tokens = word_tokenize(preprocessed_content)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stop_words]\n\n    # Remove punctuation\n    tokens = [token for token in tokens if token not in string.punctuation]\n\n    # Remove blank space tokens\n    tokens = [token for token in tokens if token.strip() != '']\n\n    # Construct the full path to the output file\n    output_file_path = os.path.join(output_directory, file_name)\n\n    # Save the preprocessed content to a new file\n    with open(output_file_path, 'w', encoding='utf-8') as file:\n        file.write(' '.join(tokens))\n\n    # Print original content before removing blank space tokens\n    print(f\"Original content of {file_name}:\")\n    print(original_content)\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Print preprocessed content after removing blank space tokens\n    print(f\"Preprocessed content of {file_name} after removing blank space tokens:\")\n    print(' '.join(tokens))\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n###blank space token\n##In the context of text processing and tokenization, a \"blank space token\" generally refers to empty or whitespace-only tokens.\n##These are tokens that consist entirely of spaces, tabs, or line breaks.\n##Removing blank space tokens involves filtering out these empty tokens from the text data.\n##However, in the code provided earlier, there is no explicit step to remove blank space tokens because the tokenization process using NLTK's\n##word_tokenize function automatically handles such cases by splitting the text into tokens based on whitespace characters.\n##Therefore, there's no need for a separate step to remove blank space tokens in this scenario. The tokenization process itself takes care of \n##excluding empty tokens.","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:03:53.555185Z","iopub.execute_input":"2024-02-09T12:03:53.555555Z","iopub.status.idle":"2024-02-09T12:03:53.587062Z","shell.execute_reply.started":"2024-02-09T12:03:53.555515Z","shell.execute_reply":"2024-02-09T12:03:53.586082Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Original content of file314.txt:\nThe Amazon advertised pictures of this item is a Fender FTE3 pre amp. The description says it's a Fishman Isys III type. I googled it and found out there's two version of pre amp type of this T Bucket 300 CE series. The one I got today is a Fishman type pre amp which is for me much better that FTE3. Out of the box, I fell inlove with the color and design. Mine is a 3 tone sunburst. The action is just right for me. The tone/sound is awesome. I hooked it up in my Vox amp and I have to say this thing really rocks. Of course you can get a better sounding acoustic/electric guitar out there for a very much expensive price. I'm a family man with two kids and I am not gonna spend a thousand bucks just for a hobby. Amplified or not I love the tone of this baby. For it's appearance, sound quality, and of course THE PRICE, I'm giving it a five stars.\n\nI uploaded some pictures (above) of the Fishman pre amp version of this T bucket series. :O)..\n\n==================================================\n\nPreprocessed content of file314.txt after removing blank space tokens:\namazon advertised pictures item fender fte3 pre amp description says 's fishman isys iii type googled found 's two version pre amp type bucket 300 ce series one got today fishman type pre amp much better fte3 box fell inlove color design mine 3 tone sunburst action right tone/sound awesome hooked vox amp say thing really rocks course get better sounding acoustic/electric guitar much expensive price 'm family man two kids gon na spend thousand bucks hobby amplified love tone baby 's appearance sound quality course price 'm giving five stars uploaded pictures fishman pre amp version bucket series ..\n\n==================================================\n\nOriginal content of file998.txt:\nI really like the simplicity of this bridge. It adjusts easy for string height and length. It comes with all the mounting screws and even a small allen wrench to make the height adjustments. The provided mounting screws are Phillips head screws. The one thing that I missed when I ordered this was the fact that it is not a bridge for string-thru the guitar body placement. The strings dead end to the stop-flair of the plate. I included a picture of this so it may help to make others aware that it is not for string-thru applications. No biggie tho for me, I will use it on another project now.\n\n==================================================\n\nPreprocessed content of file998.txt after removing blank space tokens:\nreally like simplicity bridge adjusts easy string height length comes mounting screws even small allen wrench make height adjustments provided mounting screws phillips head screws one thing missed ordered fact bridge string-thru guitar body placement strings dead end stop-flair plate included picture may help make others aware string-thru applications biggie tho use another project\n\n==================================================\n\nOriginal content of file603.txt:\nTruthfully, I had no idea that the even were ukulele capos. But why not? I use them on guitars and banjo, and there are certainly times when you might want to shift key without transposing so you can take advantage of open strings.\n\nRegardless, this is a well made, lightweight capo. Weight is of particular importance when dealing with an instrument that's already very small and lightweight, and hernally played without a strap. This capo won't make your soprano uke neck heavy. The soft rubber surface on the moveable jaw does a good job of pressing synthetic strings against a fret without stretching them out of tune. A useful tool for ukuleleists.\n\n==================================================\n\nPreprocessed content of file603.txt after removing blank space tokens:\ntruthfully idea even ukulele capos use guitars banjo certainly times might want shift key without transposing take advantage open strings regardless well made lightweight capo weight particular importance dealing instrument 's already small lightweight hernally played without strap capo wo n't make soprano uke neck heavy soft rubber surface moveable jaw good job pressing synthetic strings fret without stretching tune useful tool ukuleleists\n\n==================================================\n\nOriginal content of file175.txt:\nMy ES*335 fit loose and needed some padding added to keep the guitar snug, but if you don't mind doing that it's a good deal...\n\n==================================================\n\nPreprocessed content of file175.txt after removing blank space tokens:\nes*335 fit loose needed padding added keep guitar snug n't mind 's good deal ...\n\n==================================================\n\nOriginal content of file457.txt:\nI bought a used MIM strat that came with a black pick guard and creamish colored pickups. The guitar was great but the pick guard wasn't my style. I put this on and now I love the look of this guitar. Highly recommend.\n\n==================================================\n\nPreprocessed content of file457.txt after removing blank space tokens:\nbought used mim strat came black pick guard creamish colored pickups guitar great pick guard n't style put love look guitar highly recommend\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}